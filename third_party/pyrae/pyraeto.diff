b'--- pyrae.py\t(original)'
b'+++ pyrae.py\t(refactored)'
b'@@ -1,16 +1,18 @@'
b' #!/usr/bin/python3'
b' # -*- coding: UTF-8 -*-'
b' '
b'+from __future__ import absolute_import'
b' import ctypes'
b'-import urllib.parse'
b'+import urllib2, urllib, urlparse'
b' import bs4'
b' import requests'
b'+from itertools import izip'
b' '
b' s = requests.Session()'
b' '
b' '
b'-class _Shared:'
b"-    PARSER = 'lxml'"
b'+class _Shared(object):'
b"+    PARSER = u'lxml'"
b' '
b'     def __init__(self):'
b'         pass'
b'@@ -21,16 +23,16 @@'
b'         arr = [s1] * n'
b'         chlg = None'
b' '
b'-        for _i in range(m-1):'
b'-            for j in range(n-1, -1, -1):'
b'-                arr[j] = chr(ord(arr[j]) + 1)'
b'+        for _i in xrange(m-1):'
b'+            for j in xrange(n-1, -1, -1):'
b'+                arr[j] = unichr(ord(arr[j]) + 1)'
b' '
b'                 if arr[j] <= s2:'
b'                     break'
b' '
b'                 arr[j] = s1'
b' '
b"-            chlg = ''.join(arr)"
b"+            chlg = u''.join(arr)"
b'             crc = -1'
b' '
b'             for k in chlg + slt:'
b'@@ -48,26 +50,26 @@'
b'     @staticmethod'
b'     def get_payload(r, rf):'
b'         try:'
b'-            tmp = r.index(\'document.forms[0].elements[1].value=\\"\') + 37'
b"-            first = r[tmp:r.index(':', tmp)]"
b'-'
b'-            tmp = r.index(\'var slt = \\"\') + 11'
b'-            slt = r[tmp:r.index(\'\\"\', tmp)]'
b'-'
b"-            tmp = r.index('var c = ') + 8"
b"-            c = int(r[tmp:r.index('\\r', tmp)])"
b'-'
b"-            tmp = r.index('var s1 = \\'') + 10"
b"-            s1 = r[tmp:r.index('\\'', tmp)]"
b'-'
b"-            tmp = r.index('var s2 = \\'') + 10"
b"-            s2 = r[tmp:r.index('\\'', tmp)]"
b'-'
b"-            tmp = r.index('var n = ') + 8"
b"-            n = int(r[tmp:r.index('\\n', tmp)])"
b'-'
b'-            tmp = r.index(\'var table = \\"\') + 13'
b'-            table = r[tmp:r.index(\'\\"\', tmp)]'
b'+            tmp = r.index(u\'document.forms[0].elements[1].value=\\"\') + 37'
b"+            first = r[tmp:r.index(u':', tmp)]"
b'+'
b'+            tmp = r.index(u\'var slt = \\"\') + 11'
b'+            slt = r[tmp:r.index(u\'\\"\', tmp)]'
b'+'
b"+            tmp = r.index(u'var c = ') + 8"
b"+            c = int(r[tmp:r.index(u'\\r', tmp)])"
b'+'
b"+            tmp = r.index(u'var s1 = \\'') + 10"
b"+            s1 = r[tmp:r.index(u'\\'', tmp)]"
b'+'
b"+            tmp = r.index(u'var s2 = \\'') + 10"
b"+            s2 = r[tmp:r.index(u'\\'', tmp)]"
b'+'
b"+            tmp = r.index(u'var n = ') + 8"
b"+            n = int(r[tmp:r.index(u'\\n', tmp)])"
b'+'
b'+            tmp = r.index(u\'var table = \\"\') + 13'
b'+            table = r[tmp:r.index(u\'\\"\', tmp)]'
b'         except ValueError:'
b'             return None'
b' '
b'@@ -76,16 +78,16 @@'
b'         if chlg is None:'
b'             return None'
b' '
b"-        cr = ':'.join([first, chlg, slt, str(c)])"
b'-'
b"-        return [['TS017111a7_id', '3'],"
b"-                ['TS017111a7_cr', cr],"
b"-                ['TS017111a7_76', '0'],"
b"-                ['TS017111a7_86', '0'],"
b"-                ['TS017111a7_md', '1'],"
b"-                ['TS017111a7_rf', rf],"
b"-                ['TS017111a7_ct', '0'],"
b"-                ['TS017111a7_pd', '0']]"
b"+        cr = u':'.join([first, chlg, slt, unicode(c)])"
b'+'
b"+        return [[u'TS017111a7_id', u'3'],"
b"+                [u'TS017111a7_cr', cr],"
b"+                [u'TS017111a7_76', u'0'],"
b"+                [u'TS017111a7_86', u'0'],"
b"+                [u'TS017111a7_md', u'1'],"
b"+                [u'TS017111a7_rf', rf],"
b"+                [u'TS017111a7_ct', u'0'],"
b"+                [u'TS017111a7_pd', u'0']]"
b' '
b'     @staticmethod'
b'     def do_request(request_url, rf, do_post=True):'
b'@@ -106,12 +108,12 @@'
b'             return r'
b' '
b' '
b'-class DLE:'
b"-    HOST = 'http://dle.rae.es'"
b"-    URL_RANDOM_WORD = HOST + '/srv/random'"
b"-    URL_TODAYS_WORD = HOST + '/srv/wotd'"
b"-    URL_FETCH = HOST + '/srv/fetch'"
b"-    URL_SEARCH = HOST + '/srv/search'"
b'+class DLE(object):'
b"+    HOST = u'http://dle.rae.es'"
b"+    URL_RANDOM_WORD = HOST + u'/srv/random'"
b"+    URL_TODAYS_WORD = HOST + u'/srv/wotd'"
b"+    URL_FETCH = HOST + u'/srv/fetch'"
b"+    URL_SEARCH = HOST + u'/srv/search'"
b'     MAX_LEMMAS_PAGE = 200'
b' '
b'     def __init__(self):'
b'@@ -134,13 +136,13 @@'
b' '
b'     @staticmethod'
b'     def conjugate_id(verb_id):'
b"-        r = _Shared.do_request(DLE.URL_FETCH + '?id=' + verb_id, 'http://www.rae.es/')"
b'-'
b'-        if r.status_code != requests.codes.ok:'
b'-            return None'
b'-'
b'-        soup = bs4.BeautifulSoup(r.text, _Shared.PARSER)'
b"-        cnj = soup.find('table', class_='cnj')"
b"+        r = _Shared.do_request(DLE.URL_FETCH + u'?id=' + verb_id, u'http://www.rae.es/')"
b'+'
b'+        if r.status_code != requests.codes.ok:'
b'+            return None'
b'+'
b'+        soup = bs4.BeautifulSoup(r.text, _Shared.PARSER)'
b"+        cnj = soup.find(u'table', class_=u'cnj')"
b' '
b'         if cnj is None:'
b'             return None'
b'@@ -148,10 +150,10 @@'
b'         data = []'
b'         h = []'
b' '
b"-        for row in cnj.find_all('tr'):"
b"-            cells = [cell.text.strip() for cell in row.find_all('td')]"
b"+        for row in cnj.find_all(u'tr'):"
b"+            cells = [cell.text.strip() for cell in row.find_all(u'td')]"
b'             data.append([cell for cell in cells if cell])'
b"-            heads = [header.text.strip() for header in row.find_all('th')]"
b"+            heads = [header.text.strip() for header in row.find_all(u'th')]"
b'             h.append([header for header in heads if header])'
b' '
b'         data = [e for e in data if e]'
b'@@ -160,14 +162,14 @@'
b'         vc.append([h[1][0], data[0][0]])'
b'         vc.append([h[1][1], data[0][1]])'
b'         vc.append([h[3][0], data[1][0]])'
b"-        vc.append(DLE._conjugate(h[5][0] + ' ' + h[6][3], data[2:10], 1))"
b"-        vc.append(DLE._conjugate(h[5][0] + ' ' + h[6][4], data[2:10], 2))"
b"-        vc.append(DLE._conjugate(h[5][0] + ' ' + h[15][0], data[10:18], 1))"
b"-        vc.append(DLE._conjugate(h[5][0] + ' ' + h[15][1], data[10:18], 2))"
b"-        vc.append(DLE._conjugate(h[5][0] + ' ' + h[24][0], data[18:26], 1))"
b"-        vc.append(DLE._conjugate(h[33][0] + ' ' + h[34][3], data[26:34], 1))"
b"-        vc.append(DLE._conjugate(h[33][0] + ' ' + h[34][4], data[26:34], 2))"
b"-        vc.append(DLE._conjugate(h[33][0] + ' ' + h[43][0], data[34:42], 1))"
b"+        vc.append(DLE._conjugate(h[5][0] + u' ' + h[6][3], data[2:10], 1))"
b"+        vc.append(DLE._conjugate(h[5][0] + u' ' + h[6][4], data[2:10], 2))"
b"+        vc.append(DLE._conjugate(h[5][0] + u' ' + h[15][0], data[10:18], 1))"
b"+        vc.append(DLE._conjugate(h[5][0] + u' ' + h[15][1], data[10:18], 2))"
b"+        vc.append(DLE._conjugate(h[5][0] + u' ' + h[24][0], data[18:26], 1))"
b"+        vc.append(DLE._conjugate(h[33][0] + u' ' + h[34][3], data[26:34], 1))"
b"+        vc.append(DLE._conjugate(h[33][0] + u' ' + h[34][4], data[26:34], 2))"
b"+        vc.append(DLE._conjugate(h[33][0] + u' ' + h[43][0], data[34:42], 1))"
b'         vc.append(h[52][0])'
b'         vc.append([data[42][0], data[42][1]])'
b'         vc.append([data[43][0], data[43][1]])'
b'@@ -193,14 +195,14 @@'
b' '
b'     @staticmethod'
b'     def _request_word(word, after_host, m=None):'
b"-        url = DLE.HOST + '/?w=' + word"
b"+        url = DLE.HOST + u'/?w=' + word"
b'         url2 = DLE.HOST + after_host + word'
b' '
b'         if m is not None:'
b'             url += m'
b'             url2 += m'
b' '
b"-        if _Shared.do_request(url, 'http://www.rae.es/') is None:"
b"+        if _Shared.do_request(url, u'http://www.rae.es/') is None:"
b'             return None'
b' '
b'         r = _Shared.do_request(url2, url2)'
b'@@ -214,18 +216,18 @@'
b'     def _options(soup):'
b'         results = []'
b' '
b"-        for op in soup.find_all('a'):"
b"-            words = op.text.split('; ')"
b"-            word_ids = op.get('href').replace('fetch?id=', '').split('|')"
b'-'
b'-            for word, word_id in zip(words, word_ids):'
b"+        for op in soup.find_all(u'a'):"
b"+            words = op.text.split(u'; ')"
b"+            word_ids = op.get(u'href').replace(u'fetch?id=', u'').split(u'|')"
b'+'
b'+            for word, word_id in izip(words, word_ids):'
b'                 results.append([word, word_id])'
b' '
b'         return results'
b' '
b'     @staticmethod'
b'     def search_id(word_id):'
b"-        payload = {'id': word_id}"
b"+        payload = {u'id': word_id}"
b'         r = s.get(DLE.URL_FETCH, data=payload)'
b' '
b'         if r.status_code != requests.codes.ok:'
b'@@ -241,12 +243,12 @@'
b'     def search_word(word, m=None):'
b'         s.cookies.clear()'
b' '
b"-        soup = DLE._request_word(word, '/srv/search?w=', m)"
b"+        soup = DLE._request_word(word, u'/srv/search?w=', m)"
b' '
b'         if soup is None:'
b'             return None'
b' '
b"-        f0 = soup.find('div', id_='f0')"
b"+        f0 = soup.find(u'div', id_=u'f0')"
b' '
b'         verb_id = None'
b' '
b'@@ -259,34 +261,34 @@'
b'             if result is None:'
b'                 return None'
b' '
b"-            e2 = soup.find('a', class_='e2')"
b"+            e2 = soup.find(u'a', class_=u'e2')"
b' '
b'             if e2 is not None:'
b"-                verb_id = e2['href'].replace('fetch?id=', '')"
b"+                verb_id = e2[u'href'].replace(u'fetch?id=', u'')"
b' '
b'         return result if isinstance(result, list) else [result, verb_id]'
b' '
b'     @staticmethod'
b'     def exact(word):'
b"-        return DLE.search_word(word, '&m=30')"
b"+        return DLE.search_word(word, u'&m=30')"
b' '
b'     @staticmethod'
b'     def starts_with(prefix):'
b"-        return DLE.search_word(prefix, '&m=31')"
b"+        return DLE.search_word(prefix, u'&m=31')"
b' '
b'     @staticmethod'
b'     def ends_with(suffix):'
b"-        return DLE.search_word(suffix, '&m=32')"
b"+        return DLE.search_word(suffix, u'&m=32')"
b' '
b'     @staticmethod'
b'     def contains(substring):'
b"-        return DLE.search_word(substring, '&m=33')"
b"+        return DLE.search_word(substring, u'&m=33')"
b' '
b'     @staticmethod'
b'     def anagrams(word):'
b'         s.cookies.clear()'
b' '
b"-        soup = DLE._request_word(word, '/srv/anagram?w=')"
b"+        soup = DLE._request_word(word, u'/srv/anagram?w=')"
b' '
b'         if soup is not None:'
b'             return DLE._options(soup)'
b'@@ -295,10 +297,10 @@'
b'     def todays_word():'
b'         s.cookies.clear()'
b' '
b"-        if _Shared.do_request(DLE.HOST + '/?w=', 'http://www.rae.es/') is None:"
b'-            return None'
b'-'
b"-        payload = {'': 'diccionario'}"
b"+        if _Shared.do_request(DLE.HOST + u'/?w=', u'http://www.rae.es/') is None:"
b'+            return None'
b'+'
b"+        payload = {u'': u'diccionario'}"
b'         r = s.get(DLE.URL_SEARCH, data=payload)'
b' '
b'         if r.status_code != requests.codes.ok:'
b'@@ -311,13 +313,13 @@'
b' '
b'         soup = bs4.BeautifulSoup(r.text, _Shared.PARSER)'
b'         word = soup.a'
b"-        word_id = word['href'].replace('id=', '')"
b"+        word_id = word[u'href'].replace(u'id=', u'')"
b' '
b'         return [word.text, word_id]'
b' '
b'     @staticmethod'
b'     def get_lemmas():'
b"-        letters = 'a\xc3\xa1bcde\xc3\xa9fghi\xc3\xadjklmn\xc3\xb1o\xc3\xb3pqrstu\xc3\xbavwxyz'"
b"+        letters = u'a\xc3\xa1bcde\xc3\xa9fghi\xc3\xadjklmn\xc3\xb1o\xc3\xb3pqrstu\xc3\xbavwxyz'"
b' '
b'         prefix = letters[0]'
b'         result = []'
b'@@ -344,15 +346,15 @@'
b'                     prefix = prefix[:-1] + letters[i + 1]'
b' '
b'             if prefix == letters[-1]:'
b"-                prefix = ''"
b"+                prefix = u''"
b' '
b'         result.sort()'
b' '
b'         return result'
b' '
b' '
b'-class DPD:'
b"-    URL_SEARCH = 'http://lema.rae.es/dpd/?key='"
b'+class DPD(object):'
b"+    URL_SEARCH = u'http://lema.rae.es/dpd/?key='"
b' '
b'     def __init__(self):'
b'         pass'
b'@@ -361,7 +363,7 @@'
b'     def search(word):'
b'         s.cookies.clear()'
b' '
b'-        w = urllib.parse.quote_plus(word)'
b'+        w = urllib.quote_plus(word)'
b'         r = _Shared.do_request(DPD.URL_SEARCH + w, DPD.URL_SEARCH + w)'
b' '
b'         if r is None:'
b'@@ -374,7 +376,7 @@'
b'             return article.text'
b' '
b' '
b'-class DEJ:'
b'+class DEJ(object):'
b'     def __init__(self):'
b'         pass'
b' '
b'@@ -382,5 +384,5 @@'
b' def main():'
b'     pass'
b' '
b"-if __name__ == '__main__':"
b"+if __name__ == u'__main__':"
b'     main()'
